import time
import requests
import logging
import re
import json
import os  # æ·»åŠ  os æ¨¡å—çš„å¯¼å…¥
import csv # æ·»åŠ csv æ¨¡å—çš„å¯¼å…¥
import math
import pandas as pd
from tqdm import tqdm


# è·å–è„šæœ¬æ ¹ç›®å½•
root_dir = os.getcwd()  # æˆ–è€…ä½¿ç”¨ os.path.dirname(os.path.abspath(__file__))

# è·å–ä¸Šå±‚ç›®å½•
parent_dir = os.path.dirname(root_dir)

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler(os.path.join(root_dir, 'my_log_file.log'))  # ä¿®æ”¹è¿™è¡Œ
    ]
)

logging.info(f"æ—¥å¿—æ–‡ä»¶ä¿å­˜åœ¨ï¼š{os.path.join(root_dir, 'my_log_file.log')}")

def get_total_issue_count(lottery_id):
    """
    é€šè¿‡æ¥å£è‡ªåŠ¨è·å–è¯¥å½©ç§åœ¨ç³»ç»Ÿä¸­çš„æ€»è®°å½•æ•°ï¼Œæ— éœ€æ¯å¹´æ‰‹åŠ¨ç»´æŠ¤ã€‚
    ä½¿ç”¨ä¸€ä¸ªè¾ƒå¤§ï¼ˆå‡è®¾å¤§äºå†å²æ€»æœŸæ•°ï¼‰çš„ issueCount æ¥è§¦å‘ API è¿”å›çœŸå®çš„ 'total'ã€‚
    """
    try:
        # è¯·æ±‚è¾ƒå¤§çš„æœŸæ•°ï¼ŒpageSize=1 å³å¯ï¼Œç›®çš„æ˜¯è·å–è¿”å› JSON ä¸­çš„ 'total' å­—æ®µ
        # 100000 å·²ç»è¿œè¶…ç›®å‰æ‰€æœ‰å½©ç§çš„æ€»æœŸæ•°ï¼ˆå¦‚åŒè‰²çƒçº¦ 3400 æœŸï¼‰
        response = requests_data(1, 100000, lottery_id)
        if response is None:
            return 0

        match = re.search(r"\((.*)\)", response)
        if match:
            response = match.group(1)

        content = json.loads(response)
        total_count = int(content.get('total', 0))
        
        if total_count > 0:
            logging.info(f"ğŸ“Œ å½©ç§ ID {lottery_id} è‡ªåŠ¨æ£€æµ‹åˆ°ç³»ç»Ÿæ€»æœŸæ•°: {total_count}")
            return total_count
        else:
            # å¦‚æœè·å–å¤±è´¥ï¼Œå°è¯•é€šè¿‡è·å–ä¸€æœŸæ•°æ®æ¥é€šè¿‡ latest_issue ä¼°ç®—ï¼ˆä¿ç•™åŸé€»è¾‘ä½œä¸º backupï¼Ÿï¼‰
            # ä½†ç»è¿‡æµ‹è¯•ï¼Œtotal å­—æ®µæ˜¯éå¸¸å¯é çš„ï¼Œè¿™é‡Œç›´æ¥è¿”å› 0 å¹¶åœ¨è°ƒç”¨å¤„å¤„ç†
            logging.warning(f"âš ï¸ å½©ç§ ID {lottery_id} æ¥å£è¿”å›çš„æ€»æœŸæ•°ä¸º 0 æˆ–æ— æ•ˆ")
            return 0
    except Exception as e:
        logging.error(f"âŒ è‡ªåŠ¨è·å–ç³»ç»Ÿæ€»æœŸæ•°å‡ºé”™: {e}")
        return 0


def requests_data(pages, issue_count, ID, start_issue='', end_issue=''):
    headers = {
        'Connection': 'keep-alive',
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.117 Safari/537.36',
        'Accept': '*/*',
        'Sec-Fetch-Site': 'same-site',
        'Sec-Fetch-Mode': 'no-cors',
        'Referer': 'https://www.zhcw.com/kjxx/',
        'Accept-Encoding': 'gzip, deflate, br',
        'Accept-Language': 'zh-CN,zh;q=0.9',
    }

    timestamp = int(time.time() * 1000)
    callback = f'jQuery1122035713028555611515_{timestamp}'
    tt = '0.123456789'
    _ = timestamp + 10
    params = {
        'callback': callback,
        'transactionType': '10001001',
        'lotteryId': ID,
        'issueCount': issue_count,
        'startDate': '',
        'endDate': '',
        'type': '0',
        'pageNum': pages,
        'pageSize': '100',
        'tt': tt,
        '_': _,
    }
    if start_issue and end_issue :
         params['startIssue'] = start_issue
         params['endIssue'] = end_issue

    try:
        response = requests.get('https://jc.zhcw.com/port/client_json.php', headers=headers, params=params).content.decode('utf-8')
        return response
    except requests.exceptions.RequestException as e:
        logging.error(f"ç½‘ç»œè¯·æ±‚é”™è¯¯: {e}")
        return None

def get_latest_issue_from_system(lottry_id):
    """è·å–ç³»ç»Ÿä¸­æœ€æ–°çš„æœŸå·"""
    try:
        response = requests_data(1, 1, lottry_id)
        if response is None:
            return None

        match = re.search(r"\((.*)\)", response)
        if match:
            response = match.group(1)

        content = json.loads(response)
        latest_issue = content['data'][0]['issue']
        return latest_issue
    except Exception as e:
        logging.error(f"è·å–ç³»ç»Ÿæœ€æ–°æœŸå·å‡ºé”™: {e}")
        return None

def parse_lottery_data(json_data):
    """è§£æ JSONP å“åº”ï¼Œå¹¶æå– data å­—æ®µï¼Œè½¬æ¢æˆæ ‡å‡†å­—æ®µæ ¼å¼"""
    try:
        # è§£æ JSONP ç»“æ„
        match = re.search(r"\((.*)\);?$", json_data)
        if not match:
            logging.error("âŒ æ— æ³•æå– JSON å†…å®¹")
            return None

        json_str = match.group(1)
        data = json.loads(json_str)

        if data.get("resCode") != "000000":
            logging.error(f"âŒ æ¥å£è¿”å›é”™è¯¯: {data.get('resMsg')}")
            return None

        raw_records = data.get("data", [])
        if not raw_records:
            logging.warning("âš ï¸ æœªæå–åˆ°æœ‰æ•ˆæ•°æ®")
            return None

        structured_data = []
        for record in raw_records:
            if isinstance(record, dict):
                # è§£æçº¢çƒã€è“çƒ
                record = extract_ball_numbers(record)

                # **âœ… ç›´æ¥ä¿ç•™ `winnerDetails`ï¼Œä¸è§£æ**
                structured_data.append(record)

        return structured_data

    except json.JSONDecodeError as e:
        logging.error(f"âŒ JSON è§£æé”™è¯¯: {e}, åŸå§‹æ•°æ®ç‰‡æ®µ: {json_data[:200]}...")
        return None
    except Exception as e:
        logging.error(f"âŒ è§£æå‡ºé”™: {e}")
        return None


def extract_ball_numbers(record):
    """
    è§£æ frontWinningNum å’Œ backWinningNumï¼ŒåŠ¨æ€ç”Ÿæˆçº¢çƒå’Œè“çƒåˆ—
    :param record: å­—å…¸ï¼ŒåŒ…å« 'frontWinningNum' å’Œ 'backWinningNum'
    :return: è§£æåçš„æ–°å­—å…¸ï¼ŒåŒ…å« 'çº¢çƒ1'ã€'çº¢çƒ2'... å’Œ 'ç¯®çƒ'/'è“çƒ1', 'è“çƒ2'...
    """
    new_record = record.copy()  # å¤åˆ¶åŸå§‹æ•°æ®ï¼Œé¿å…ä¿®æ”¹åŸæ•°æ®

    # è§£æ frontWinningNumï¼ˆçº¢çƒï¼‰
    front_numbers = record.get("frontWinningNum", "").split()
    for i, num in enumerate(front_numbers, start=1):
        new_record[f"çº¢çƒ{i}"] = int(num)  # åŠ¨æ€åˆ›å»ºåˆ—

    # è§£æ backWinningNumï¼ˆè“çƒï¼‰
    back_numbers = record.get("backWinningNum", "").split()
    if len(back_numbers) == 1:
        new_record["ç¯®çƒ"] = int(back_numbers[0])  # åªæœ‰ä¸€ä¸ªæ—¶å« "ç¯®çƒ"
    else:
        for i, num in enumerate(back_numbers, start=1):
            new_record[f"è“çƒ{i}"] = int(num)  # å¤šä¸ªæ—¶å« "è“çƒ1", "è“çƒ2"...

    return new_record



def save_to_csv(data, filename):
    """å°†æ•°æ®ä¿å­˜åˆ° CSV æ–‡ä»¶ï¼Œè‡ªåŠ¨åˆ›å»º data ç›®å½•"""
    try:
        if not data:
            logging.warning("æ²¡æœ‰æ•°æ®å¯ä»¥ä¿å­˜åˆ° CSV æ–‡ä»¶")
            return
        # è·å–è„šæœ¬æ ¹ç›®å½•
        root_dir = os.getcwd()  # æˆ–è€…ä½¿ç”¨ os.path.dirname(os.path.abspath(__file__))

        # æ„å»ºå®Œæ•´çš„æ–‡ä»¶è·¯å¾„
        filepath= os.path.join(root_dir, "data", filename)
        # ç¡®ä¿ data ç›®å½•å­˜åœ¨
        # os.makedirs(os.path.join(root_dir, "data"), exist_ok=True)

        with open(filepath, 'w', newline='', encoding='utf-8-sig') as csvfile:
            writer = csv.writer(csvfile)
            header = data[0].keys()
            writer.writerow(header)
            for row in data:
                writer.writerow(row.values())
        logging.info(f"æ•°æ®å·²æˆåŠŸä¿å­˜åˆ° {filepath}")
    except Exception as e:
        logging.error(f"ä¿å­˜ CSV æ–‡ä»¶å‡ºé”™: {e}")


def get_lottery_data(lottery_id, lottery_name):
    """è·å–å½©ç¥¨æ•°æ®ï¼ŒåŠ¨æ€è®¡ç®— `total_count` å¹¶è‡ªåŠ¨åˆ†é¡µä¸‹è½½"""
    filename = f"{lottery_name}_lottery_data.csv"

    # è‡ªåŠ¨è·å–å½“å‰ç³»ç»Ÿä¸­è¯¥å½©ç§çš„æ€»æœŸæ•°
    total_count = get_total_issue_count(lottery_id)
    
    if total_count == 0:
        logging.error(f"âŒ æ— æ³•ç¡®å®š {lottery_name} çš„æ€»æœŸæ•°ï¼Œè·³è¿‡ä¸‹è½½ã€‚")
        return

    # è®¡ç®—æ€»é¡µæ•°
    total_pages = math.floor(total_count / 100 + 1) if total_count % 100 == 0 else math.floor(total_count / 100 + 2)
    logging.info(f"ğŸ“„ {lottery_name} è®¡ç®—æ€»é¡µæ•°: {total_pages}")

    all_data = []

    for page in tqdm(range(1, total_pages), desc=f"ğŸ“¥ ä¸‹è½½ {lottery_name} æ•°æ®"):
        json_data = requests_data(page, total_count, lottery_id)
        if json_data:
            lottery_data = parse_lottery_data(json_data) # åˆ†è§£çº¢çƒå’Œè“çƒæ•°æ®åˆ°å•ç‹¬åˆ—
            if lottery_data:
                all_data.extend(lottery_data)

    # ä¿å­˜æ•°æ®
    save_to_csv(all_data, filename)

def process_ssq_data(input_csv="data/åŒè‰²çƒ_lottery_data.csv", output_csv="data/åŒè‰²çƒ_processed_data.csv"):
    """
    è‡ªç»™è‡ªè¶³çš„æ•°æ®å¤„ç†å‡½æ•°ï¼š
    1. ä»åŸå§‹ CSV è¯»å–ä¸‹è½½å¥½çš„æ•°æ®
    2. è§£æä¸­å¥–ç­‰çº§å’Œå¥–é‡‘
    3. è®¡ç®—å¥‡å¶ã€å¤§å°ã€ä¸‰åŒºã€è¿å·ã€è·³å·ç­‰æŒ‡æ ‡
    4. ç»“æœä¿å­˜ä¸º app.py ä½¿ç”¨çš„æ ¼å¼
    """
    if not os.path.exists(input_csv):
        logging.error(f"æ‰¾ä¸åˆ°è¾“å…¥æ–‡ä»¶: {input_csv}")
        return

    logging.info(f"å¼€å§‹åæœŸå¤„ç† {input_csv} ...")
    df = pd.read_csv(input_csv)

    # å­—æ®µé‡å‘½åæ˜ å°„
    mapping = {
        'issue': 'æœŸå·',
        'openTime': 'å¼€å¥–æ—¥æœŸ',
        'week': 'WeekDay',
        'saleMoney': 'æ€»é”€å”®é¢(å…ƒ)',
        'prizePoolMoney': 'å¥–æ± é‡‘é¢(å…ƒ)',
        'ç¯®çƒ': 'è“çƒ'
    }
    df = df.rename(columns=mapping)

    # è§£æä¸­å¥–ä¿¡æ¯
    awards = ['ä¸€ç­‰å¥–', 'äºŒç­‰å¥–', 'ä¸‰ç­‰å¥–', 'å››ç­‰å¥–', 'äº”ç­‰å¥–', 'å…­ç­‰å¥–']
    for award in awards:
        df[f'{award}æ³¨æ•°'] = 0
        df[f'{award}å¥–é‡‘'] = 0

    def parse_awards(row):
        details_str = row['winnerDetails']
        if pd.isna(details_str) or not details_str:
            return row
        try:
            # å¤„ç†å•å¼•å·å­—ç¬¦ä¸²ï¼Œeval åœ¨å·²çŸ¥æ•°æ®æºä¸‹æ˜¯å¿«æ·æ–¹å¼
            details = eval(details_str)
            for item in details:
                award_etc = item.get('awardEtc')
                base = item.get('baseBetWinner', {})
                try:
                    level = int(award_etc)
                    if 1 <= level <= 6:
                        row[f'{awards[level-1]}æ³¨æ•°'] = base.get('awardNum', 0)
                        row[f'{awards[level-1]}å¥–é‡‘'] = base.get('awardMoney', 0)
                except: continue
        except: pass
        return row

    df = df.apply(parse_awards, axis=1)

    # æ•°å­—ç±»å‹è½¬æ¢
    red_ball_columns = ['çº¢çƒ1', 'çº¢çƒ2', 'çº¢çƒ3', 'çº¢çƒ4', 'çº¢çƒ5', 'çº¢çƒ6']
    for col in red_ball_columns:
        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)

    def count_consecutive(nums):
        nums.sort()
        n, counts = len(nums), {'äºŒè¿': 0, 'ä¸‰è¿': 0, 'å››è¿': 0, 'äº”è¿': 0, 'å…­è¿': 0}
        i = 0
        while i < n - 1:
            if nums[i] + 1 == nums[i + 1]:
                length = 2
                while i + length < n and nums[i + length - 1] + 1 == nums[i + length]: length += 1
                key = f"{['', '', 'äºŒ', 'ä¸‰', 'å››', 'äº”', 'å…­'][length]}è¿"
                if 2 <= length <= 6: counts[key] += 1
                i += length
            else: i += 1
        return counts

    def count_jumps(nums):
        nums.sort()
        n, counts = len(nums), {'äºŒè·³': 0, 'ä¸‰è·³': 0, 'å››è·³': 0, 'äº”è·³': 0, 'å…­è·³': 0}
        i = 0
        while i < n - 1:
            diff = nums[i + 1] - nums[i]
            if diff >= 2:
                length = 1
                while i + length < n - 1 and nums[i + length + 1] - nums[i + length] == diff: length += 1
                jump_key = None
                if diff == 2: jump_key = {1: 'äºŒè·³', 2: 'ä¸‰è·³', 3: 'å››è·³', 4: 'äº”è·³', 5: 'å…­è·³'}.get(length)
                elif diff in [3,4,5,6] and (length == diff-1 or length == diff):
                    jump_key = {2: 'ä¸‰è·³', 3: 'å››è·³', 4: 'äº”è·³', 5: 'å…­è·³'}.get(length)
                if jump_key:
                    counts[jump_key] += 1
                    i += (length + 1)
                else: i += 1
            else: i += 1
        return counts

    df = df.sort_values('æœŸå·', ascending=False).reset_index(drop=True)
    stats = []
    for i in range(len(df)):
        nums = sorted(df.loc[i, red_ball_columns].tolist())
        odd = sum(1 for n in nums if n % 2 == 1)
        small = sum(1 for n in nums if n <= 16)
        z1 = sum(1 for n in nums if 1 <= n <= 11)
        z2 = sum(1 for n in nums if 12 <= n <= 22)
        z3 = sum(1 for n in nums if 23 <= n <= 33)
        rep, adj = 0, 0
        if i < len(df) - 1:
            prev = set(df.loc[i+1, red_ball_columns].tolist())
            rep = len(set(nums) & prev)
            adj = sum(1 for n in nums if (n-1 in prev or n+1 in prev))
        
        sum_val = sum(nums)
        ac = len(set(abs(a-b) for a in nums for b in nums if a > b)) - 5
        
        res = {
            'å¥‡æ•°': odd, 'å¶æ•°': 6 - odd, 'å°å·': small, 'å¤§å·': 6 - small,
            'ä¸€åŒº': z1, 'äºŒåŒº': z2, 'ä¸‰åŒº': z3, 'é‡å·': rep, 'é‚»å·': adj, 'å­¤å·': 6-rep-adj,
            'å’Œå€¼': sum_val, 'AC': ac, 'è·¨åº¦': max(nums) - min(nums)
        }
        res.update(count_consecutive(nums))
        res.update(count_jumps(nums))
        stats.append(res)

    final_df = pd.concat([df, pd.DataFrame(stats)], axis=1)
    final_df.to_csv(output_csv, index=False, encoding='utf-8-sig')
    logging.info(f"âœ… åæœŸå¤„ç†å®Œæˆ: {output_csv}")

# =========== ä¸»ç¨‹åº =========== #
if __name__ == "__main__":
    lotteries = {
        "ssq": {"id": "1", "jc": "åŒè‰²çƒ"},
        "d3": {"id": "2", "jc": "ç¦å½©3D"},
        "qlc": {"id": "3", "jc": "ä¸ƒä¹å½©"},
        "kl8": {"id": "6", "jc": "å¿«ä¹8"},
        "dlt": {"id": "281", "jc": "è¶…çº§å¤§ä¹é€"},
        "pl3": {"id": "283", "jc": "æ’åˆ—ä¸‰"},
        "pl5": {"id": "284", "jc": "æ’åˆ—äº”"},
        "xqxc": {"id": "287", "jc": "ä¸ƒæ˜Ÿå½©"},
    }

    for key, value in lotteries.items():
        get_lottery_data(value["id"], value["jc"])

    # ä¸‹è½½å®Œæˆåï¼Œè‡ªåŠ¨è§¦å‘åŒè‰²çƒæ•°æ®çš„åæœŸåŠ å·¥å¤„ç†
    process_ssq_data()